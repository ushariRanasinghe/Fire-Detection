{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":449399,"sourceType":"datasetVersion","datasetId":204723},{"sourceId":6343158,"sourceType":"datasetVersion","datasetId":3652173},{"sourceId":111486,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":93422,"modelId":117634}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport shutil\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import regularizers\nimport cv2\nfrom sklearn.model_selection import train_test_split\n\nimport rasterio\nfrom sklearn.utils import shuffle\nimport openslide\n\nimport os\nimport sys\nfrom shutil import copyfile, move\nfrom tqdm import tqdm\nimport h5py\nimport random\nfrom random import randint\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Input\nimport requests\nfrom io import BytesIO\nfrom PIL import Image\nfrom tensorflow.keras.layers import InputLayer, Input\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout, Activation\nfrom tensorflow.keras.layers import BatchNormalization, Reshape, MaxPooling2D, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras.losses import mean_squared_error\nimport keras as K\nfrom sklearn.metrics import cohen_kappa_score\nfrom tensorflow.keras import models\nfrom tensorflow.keras.models import load_model\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:55:56.085733Z","iopub.execute_input":"2024-09-11T16:55:56.086152Z","iopub.status.idle":"2024-09-11T16:55:56.100800Z","shell.execute_reply.started":"2024-09-11T16:55:56.086119Z","shell.execute_reply":"2024-09-11T16:55:56.099547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Image Data into dataframe","metadata":{}},{"cell_type":"code","source":"def get_image_paths_and_labels(fire_dir, non_fire_dir):\n    image_path_list = []\n    Labels = []\n    \n    fire_label = 1\n    non_fire_label = 0\n    \n    #Fetch Image paths from fire directory\n    for root, dirs, files in os.walk(fire_dir):\n        for file in files:\n            if file.endswith(('.png', '.jpg', '.jpeg')):  # Add more extensions if needed\n                image_path = os.path.join(root, file)\n                image_path_list.append(image_path)\n                Labels.append(fire_label)\n    \n    # Fetch image paths from the non_fire directory\n    for root, dirs, files in os.walk(non_fire_dir):\n        for file in files:\n            if file.endswith(('.png', '.jpg', '.jpeg')):\n                image_path = os.path.join(root, file)\n                image_path_list.append(image_path)\n                Labels.append(non_fire_label)\n    \n    return image_path_list, Labels\n\n#Create Dataframe\ndef create_image_dataframe(image_path_list, Labels):\n    # Generate unique image IDs\n    image_ids = [f\"img_{i+1}\" for i in range(len(image_path_list))]\n    \n    df = pd.DataFrame({\n        'image_id': image_ids,\n        'image_path': image_path_list,\n        'fire': Labels  #1 for fire, 0 for non-fire\n    })\n    \n    return df\n\n\nfire_dir = \"/kaggle/input/firedataset-jpg-224/FireDataset-V6-JPG-Reshaped224/train/fire\"\nnon_fire_dir = \"/kaggle/input/firedataset-jpg-224/FireDataset-V6-JPG-Reshaped224/train/non_fire\"\nimage_path_list, Labels = get_image_paths_and_labels(fire_dir, non_fire_dir)\n\n# Create the DataFrame for train set\ndf = create_image_dataframe(image_path_list, Labels)\nprint('Train Data set')\nprint(df.head())\n\nfire_dir = \"/kaggle/input/firedataset-jpg-224/FireDataset-V6-JPG-Reshaped224/test/fire\"\nnon_fire_dir = \"/kaggle/input/firedataset-jpg-224/FireDataset-V6-JPG-Reshaped224/test/non_fire\"\nimage_path_list, Labels = get_image_paths_and_labels(fire_dir, non_fire_dir)\n\n# Create DataFrame for test set\ntest_df = create_image_dataframe(image_path_list, Labels)\nprint('Test Data set')\nprint(test_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:48:48.690602Z","iopub.execute_input":"2024-09-11T16:48:48.691334Z","iopub.status.idle":"2024-09-11T16:48:55.421421Z","shell.execute_reply.started":"2024-09-11T16:48:48.691298Z","shell.execute_reply":"2024-09-11T16:48:55.420131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Shuffle and split generated dataframe into train and validation sets, with validation ratio 0.2\n\ndef shuffle_and_split(df, validation_ratio=0.2):\n    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n    \n    train_df, val_df = train_test_split(df, test_size=validation_ratio, random_state=42)\n    \n    # Reindex the resulting DataFrames from 0\n    train_df = train_df.reset_index(drop=True)\n    val_df = val_df.reset_index(drop=True)\n    \n    return train_df, val_df\n\ntrain_df, val_df = shuffle_and_split(df)\n\nprint(\"Training Set:\")\nprint(train_df.head())\n\nprint(\"\\nValidation Set:\")\nprint(val_df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:49:32.480351Z","iopub.execute_input":"2024-09-11T16:49:32.480784Z","iopub.status.idle":"2024-09-11T16:49:32.500512Z","shell.execute_reply.started":"2024-09-11T16:49:32.480740Z","shell.execute_reply":"2024-09-11T16:49:32.499035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SHAPE =(150,150,3)\nBATCH_SIZE=16\nIMG_HEIGHT= 150\nIMG_WIDTH =150","metadata":{"execution":{"iopub.status.busy":"2024-09-11T17:35:58.153298Z","iopub.execute_input":"2024-09-11T17:35:58.154036Z","iopub.status.idle":"2024-09-11T17:35:58.159977Z","shell.execute_reply.started":"2024-09-11T17:35:58.154000Z","shell.execute_reply":"2024-09-11T17:35:58.158792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Applies edge filtering, heatmap, and color masks to each image. \ndef apply_masks(image):\n    #Generates an edge mask using the Canny edge detector.\n    edge_mask = generate_edge_mask(image)\n    \n    #Heatmap mask - convert image to grayscale and apply a threshold to find bright regions\n    heatmap_mask = generate_heatmap_mask(image)\n    \n    #Color mask\n    color_mask = generate_color_mask(image)\n\n    #Apply edge mask (edge detection in grayscale)\n    edge_mask_colored = cv2.cvtColor(edge_mask, cv2.COLOR_GRAY2BGR)  # Convert to 3 channels\n    masked_image1 = cv2.bitwise_and(image, edge_mask_colored)\n\n    # Apply heatmap mask (highlight areas likely to be hot)\n    heatmap_mask_colored = cv2.applyColorMap(heatmap_mask, cv2.COLORMAP_JET)  # Apply colormap to create a heatmap effect\n    masked_image2 = cv2.addWeighted(image, 0.5, heatmap_mask_colored, 0.5, 0)  # Blend original image with heatmap\n\n    #Generates a color mask by isolating fire-like colors (reds, oranges, yellows).\n    color_mask_colored = cv2.cvtColor(color_mask, cv2.COLOR_GRAY2BGR)  # Convert to 3 channels\n    masked_image3 = cv2.bitwise_and(image, color_mask_colored)  # Highlight areas with fire-like colors\n\n    return masked_image1, masked_image2, masked_image3\n\ndef generate_edge_mask(image):\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    edges = cv2.Canny(gray_image, 100, 200)  # Thresholds for Canny edge detection\n    return edges\n\ndef generate_heatmap_mask(image):\n    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    _, heatmap_mask = cv2.threshold(gray_image, 200, 255, cv2.THRESH_BINARY)\n    return heatmap_mask\n\ndef generate_color_mask(image):\n    # Convert image to HSV color space\n    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    lower_bound = np.array([0, 100, 100])  # Lower bound for red colors\n    upper_bound = np.array([10, 255, 255])  #Upper bound for red colors\n    mask1 = cv2.inRange(hsv_image, lower_bound, upper_bound)\n\n    lower_bound = np.array([10, 100, 100])  \n    upper_bound = np.array([30, 255, 255]) \n    mask2 = cv2.inRange(hsv_image, lower_bound, upper_bound)\n\n    lower_bound = np.array([30, 100, 100])\n    upper_bound = np.array([50, 255, 255])\n    mask3 = cv2.inRange(hsv_image, lower_bound, upper_bound)\n\n    color_mask = cv2.bitwise_or(mask1, mask2)\n    color_mask = cv2.bitwise_or(color_mask, mask3)\n\n    return color_mask\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:50:16.540627Z","iopub.execute_input":"2024-09-11T16:50:16.541068Z","iopub.status.idle":"2024-09-11T16:50:16.556467Z","shell.execute_reply.started":"2024-09-11T16:50:16.541035Z","shell.execute_reply":"2024-09-11T16:50:16.555237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create custom generator to generate 3 seperate versions of the same image","metadata":{}},{"cell_type":"code","source":"\ndef custom_generator(image_path_list, Labels, batch_size=16):\n    while True:\n        for start in range(0, len(image_path_list), batch_size):\n            X_batch_1 = []\n            X_batch_2 = []\n            X_batch_3 = []\n            Y_batch = []\n            \n            # Ensure that the index doesn't exceed the size of the image_path_list\n            end = min(start + batch_size, len(image_path_list))\n\n            for i in range(start, end):\n                image_path = image_path_list[i]\n                label = Labels[i] \n                \n                # Load image \n                image = cv2.imread(image_path)\n                image = cv2.resize(image, (150, 150))  # Resize image\n                \n                # Apply masks\n                masked_image1, masked_image2, masked_image3 = apply_masks(image)\n                \n                #Normalize the images\n                masked_image1 = masked_image1 / 255.0\n                masked_image2 = masked_image2 / 255.0\n                masked_image3 = masked_image3 / 255.0\n                \n                # Append masked images to respective batches\n                X_batch_1.append(masked_image1)\n                X_batch_2.append(masked_image2)\n                X_batch_3.append(masked_image3)\n                \n                # Append the relevant label\n                Y_batch.append(label)\n            \n            # Convert to numpy arrays\n            X_batch_1 = np.array(X_batch_1)\n            X_batch_2 = np.array(X_batch_2)\n            X_batch_3 = np.array(X_batch_3)\n            \n            Y_batch = np.array(Y_batch).reshape(-1, 1)\n            \n            yield (X_batch_1, X_batch_2, X_batch_3), Y_batch\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:49:47.373569Z","iopub.execute_input":"2024-09-11T16:49:47.373996Z","iopub.status.idle":"2024-09-11T16:49:47.386561Z","shell.execute_reply.started":"2024-09-11T16:49:47.373963Z","shell.execute_reply":"2024-09-11T16:49:47.384960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"url='https://i0.wp.com/yaleclimateconnections.org/wp-content/uploads/2023/03/323_wildfireroad_1600.png?fit=1200%2C675&ssl=1'\nresponse = requests.get(url)\nimage_np = np.asarray(bytearray(response.content), dtype=np.uint8)\nimage = cv2.imdecode(image_np, cv2.IMREAD_COLOR)\nmasked_image1, masked_image2, masked_image3 = apply_masks(image)\n\n# Display the images in a 2x2 grid\nplt.figure(figsize=(10, 10))\n\n# Original image\nplt.subplot(2, 2, 1)\nplt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\nplt.title('Original Image')\nplt.axis('off')\n\n# Masked image 1\nplt.subplot(2, 2, 2)\nplt.imshow(cv2.cvtColor(masked_image1, cv2.COLOR_BGR2RGB))\nplt.title('Edge Mask')\nplt.axis('off')\n\n# Masked image 2\nplt.subplot(2, 2, 3)\nplt.imshow(cv2.cvtColor(masked_image2, cv2.COLOR_BGR2RGB))\nplt.title('Heatmap Mask')\nplt.axis('off')\n\n# Masked image 3\nplt.subplot(2, 2, 4)\nplt.imshow(cv2.cvtColor(masked_image3, cv2.COLOR_BGR2RGB))\nplt.title('Smoke Mask')\nplt.axis('off')\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:50:24.620613Z","iopub.execute_input":"2024-09-11T16:50:24.621043Z","iopub.status.idle":"2024-09-11T16:50:25.928721Z","shell.execute_reply.started":"2024-09-11T16:50:24.621009Z","shell.execute_reply":"2024-09-11T16:50:25.927158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model(IMAGE_SHAPE):\n    \"\"\"\n    Creates a CNN model with 3 input branches and a binary output.\n    \n    Parameters:\n    - IMAGE_SHAPE: Shape of each input image (height, width, channels)\n    \n    Returns:\n    - Compiled Keras model\n    \"\"\"\n    num_channels = IMAGE_SHAPE[2]\n\n    def branch(input_image):\n        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_image)\n        x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n        x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n        x = layers.GlobalAveragePooling2D()(x)\n        x = layers.Dense(128, activation='relu')(x)\n        x = layers.Dropout(0.5)(x)\n        return x\n\n    # Input layers for 3 channels\n    input_image1 = layers.Input(shape=IMAGE_SHAPE)\n    input_image2 = layers.Input(shape=IMAGE_SHAPE)\n    input_image3 = layers.Input(shape=IMAGE_SHAPE)\n\n    # Create Branches for each input\n    branch1 = branch(input_image1)\n    branch2 = branch(input_image2)\n    branch3 = branch(input_image3)\n\n    # Merge all the branches\n    merge = layers.Concatenate()([branch1, branch2, branch3])\n    dense = layers.Dense(128, activation='relu')(merge)\n    dropout = layers.Dropout(0.5)(dense)\n    output = layers.Dense(1, activation='sigmoid')(dropout)  # Use sigmoid activation for Binary output\n\n    model = models.Model(inputs=[input_image1, input_image2, input_image3], outputs=output)\n    \n    #Set the learning rate to a low value for a more stable learning curve\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n\n    return model\n\n\n# Create and compile the model\nmodel = create_model(IMAGE_SHAPE)\n\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:56:06.890799Z","iopub.execute_input":"2024-09-11T16:56:06.891205Z","iopub.status.idle":"2024-09-11T16:56:07.133337Z","shell.execute_reply.started":"2024-09-11T16:56:06.891172Z","shell.execute_reply":"2024-09-11T16:56:07.132009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"# Define callbacks\ncallbacks = [\n    ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.5),\n    EarlyStopping(monitor='val_loss', patience=3),\n    ModelCheckpoint(filepath='best_model.keras', monitor='val_loss', save_best_only=True)\n]\n\n# Instantiate the generators\ntrain_generator = custom_generator(train_df[\"image_path\"], train_df[\"fire\"], batch_size=BATCH_SIZE)\nval_generator = custom_generator(val_df[\"image_path\"], val_df[\"fire\"], batch_size=BATCH_SIZE)\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(train_df) // BATCH_SIZE,\n    validation_data=val_generator,\n    validation_steps=len(val_df) // BATCH_SIZE,\n    epochs=10,\n    callbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-11T16:56:17.580336Z","iopub.execute_input":"2024-09-11T16:56:17.580732Z","iopub.status.idle":"2024-09-11T17:35:58.150946Z","shell.execute_reply.started":"2024-09-11T16:56:17.580695Z","shell.execute_reply":"2024-09-11T17:35:58.149628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training & validation loss & accuracy\nplt.figure(figsize=(12, 5))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Training Loss', 'Validation Loss'])\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Training Accuracy', 'Validation Accuracy'])\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T17:36:08.200667Z","iopub.execute_input":"2024-09-11T17:36:08.201148Z","iopub.status.idle":"2024-09-11T17:36:09.059710Z","shell.execute_reply.started":"2024-09-11T17:36:08.201115Z","shell.execute_reply":"2024-09-11T17:36:09.058534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('multi_model.h5')\n#Load trained model\n#model = load_model('/working/mutli_model.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimg_height, img_width = 150, 150\n\n# get test images\ntest_data_dir = '/kaggle/input/firedataset-jpg-224/FireDataset-V6-JPG-Reshaped224/test'\n\n# Create test generator\ntest_gen = custom_generator(test_df['image_path'],test_df['fire'], BATCH_SIZE)\n\nloss, accuracy = model.evaluate(test_gen, steps=len(test_df['image_path']) // BATCH_SIZE, verbose=1)\n\nprint(f\"Test Loss: {loss:.4f}\")\nprint(f\"Test Accuracy: {accuracy:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-11T17:39:22.689802Z","iopub.execute_input":"2024-09-11T17:39:22.690225Z","iopub.status.idle":"2024-09-11T17:39:43.709626Z","shell.execute_reply.started":"2024-09-11T17:39:22.690194Z","shell.execute_reply":"2024-09-11T17:39:43.708228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/firedataset-jpg-224/FireDataset-V6-JPG-Reshaped224/train'\nfire_dir = os.path.join(data_dir, 'fire')\nnon_fire_dir = os.path.join(data_dir, 'non_fire')\n\nnum_images_per_class = 4\n\ndef load_image(image_path):\n    image = cv2.imread(image_path)\n    image = cv2.resize(image, (img_height, img_width))\n    return image\n\n#Preprocess images for evaluation\ndef preprocess_and_predict(image):\n    masked_image1, masked_image2, masked_image3 = apply_masks(image)\n    \n    masked_image1 = masked_image1 / 255.0\n    masked_image2 = masked_image2 / 255.0\n    masked_image3 = masked_image3 / 255.0\n    \n    # Stack the images into one input batch\n    X_batch_1 = np.expand_dims(masked_image1, axis=0)\n    X_batch_2 = np.expand_dims(masked_image2, axis=0)\n    X_batch_3 = np.expand_dims(masked_image3, axis=0)\n    \n    # Predict\n    prediction = model.predict([X_batch_1, X_batch_2, X_batch_3])\n    return prediction\n\n# Display image with prediction\ndef plot_images_with_predictions(directory, num_images):\n    img_paths = [os.path.join(directory, img) for img in os.listdir(directory)][:num_images]\n    \n    rows = 2\n    cols = num_images // 2 if num_images > 1 else 1\n    \n    plt.figure(figsize=(12, 8))\n    \n    for i, img_path in enumerate(img_paths):\n        image = load_image(img_path)\n        prediction = preprocess_and_predict(image)\n        predicted_class = 'fire' if prediction[0] > 0.5 else 'non_fire'\n        \n        plt.subplot(rows, cols, i + 1)\n        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n        plt.title(predicted_class)\n        plt.axis('off')\n\nplot_images_with_predictions(fire_dir, num_images_per_class)\nplot_images_with_predictions(non_fire_dir, num_images_per_class)\n\nplt.tight_layout()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-11T17:43:55.813930Z","iopub.execute_input":"2024-09-11T17:43:55.814414Z","iopub.status.idle":"2024-09-11T17:43:58.415155Z","shell.execute_reply.started":"2024-09-11T17:43:55.814377Z","shell.execute_reply":"2024-09-11T17:43:58.413881Z"},"trusted":true},"execution_count":null,"outputs":[]}]}